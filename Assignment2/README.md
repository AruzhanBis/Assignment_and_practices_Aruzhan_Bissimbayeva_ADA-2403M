## Assignment 2. Гетерогенная и параллельная обработка данных


## Общая структура работы

Данная работа состоит из четырёх заданий, направленных на изучение принципов параллельных вычислений на CPU и GPU, а также практическую реализацию алгоритмов с использованием технологий **OpenMP** и **CUDA**.

* **Задача 1** — теоретическое задание
* **Задачи 2 и 3** — практические задания на C++ с использованием OpenMP
* **Задача 4** — практическое задание на GPU с использованием CUDA (Google Colab)

---

## Задача 1. Введение в гетерогенную параллелизацию

**Тип:** теоретическое задание

В рамках данного задания рассматривается понятие гетерогенной параллелизации вычислений. В теоретической части раскрываются следующие аспекты:

* различия между параллельными вычислениями на CPU и GPU;
* преимущества гетерогенной параллелизации (совместное использование CPU и GPU);
* примеры реальных приложений, в которых применяется гетерогенная параллелизация (научные вычисления, обработка изображений, машинное обучение и др.).

Результатом выполнения задания является письменное теоретическое объяснение без реализации программного кода.

---

## Задача 2. Работа с массивами и OpenMP

**Тип:** практическое задание (C++)

### Описание задачи

В данном задании реализуется программа на языке C++, которая:

1. Создаёт массив из 10 000 случайных чисел;
2. Находит минимальное и максимальное значения массива:

   * в последовательной реализации;
   * с использованием параллельной обработки OpenMP;
3. Сравнивает время выполнения последовательной и параллельной реализаций.

### Используемые технологии

* Язык программирования: **C++**
* Параллелизация: **OpenMP**
* Измерение времени: `std::chrono`

### Компиляция и запуск

**Компиляция (Windows / PowerShell):**

```bash
g++ -fopenmp -O2 -std=c++17 task2.cpp -o task2.exe
```

**Запуск:**

```bash
.\task2.exe
```

**(Опционально) Указание числа потоков OpenMP:**

```powershell
$env:OMP_NUM_THREADS = '4'
```

---

## Задача 3. Параллельная сортировка выбором с OpenMP

**Тип:** практическое задание (C++)

### Описание задачи

В рамках данного задания реализуется алгоритм сортировки выбором (selection sort):

1. Последовательная реализация алгоритма;
2. Параллельная реализация с использованием OpenMP:

   * параллелизация поиска минимального элемента;
   * внешний цикл остаётся последовательным из-за зависимостей по данным;
3. Проверка производительности для массивов размером:

   * 1 000 элементов;
   * 10 000 элементов.

### Используемые технологии

* Язык программирования: **C++**
* Параллелизация: **OpenMP**
* Измерение времени: `std::chrono`

### Компиляция и запуск

**Компиляция (Windows / PowerShell):**

```bash
g++ -fopenmp -O2 -std=c++17 task3.cpp -o task3.exe
```

**Запуск:**

```bash
.\task3.exe
```

**(Опционально) Указание числа потоков OpenMP:**

```powershell
$env:OMP_NUM_THREADS = '4'
```

---

## Задача 4. Сортировка на GPU с использованием CUDA

**Тип:** практическое задание (CUDA, GPU)

### Описание задачи

В данном задании реализуется параллельная сортировка слиянием на GPU с использованием технологии CUDA. Алгоритм включает следующие этапы:

1. Создание входного массива заданного размера;
2. Разбиение массива на подмассивы, каждый из которых обрабатывается отдельным CUDA-блоком;
3. Параллельное слияние отсортированных подмассивов на GPU;
4. Замер времени выполнения сортировки для массивов размером:

   * 10 000 элементов;
   * 100 000 элементов.

Замер производительности выполняется с использованием CUDA Events и отражает только время выполнения вычислений на GPU (без учёта передачи данных между CPU и GPU).

### Используемые технологии

* Язык программирования: **CUDA C++**
* Платформа: **Google Colab (GPU)**
* Параллелизация: **CUDA kernels**
* Измерение времени: `cudaEvent`

### Компиляция и запуск (Google Colab)

В ячейке Google Colab используется следующий код:

```bash
# Компилируем и запускаем
!nvcc -arch=sm_75 cuda_task4.cu -o cuda_task4 && ./cuda_task4
```

Файл `cuda_task4.cu` создаётся непосредственно в ноутбуке с помощью директивы `%%writefile`.

---

## Заключение

В ходе выполнения данной работы были изучены и практически реализованы основные подходы к параллельной обработке данных:

* последовательные и параллельные вычисления на CPU;
* использование OpenMP для параллелизации циклов;
* реализация параллельных алгоритмов на GPU с использованием CUDA;
* измерение и анализ производительности для различных размеров входных данных.

## Автор проекта  
Студент: Aruzhan Bissimbayeva 

Группа: ADA-2403M

## Преподаватель  
Проверяющий: Sadvakassova Kuralay

