# Практическая работа 3: Параллельные алгоритмы сортировки на CUDA

**Студент:** Aruzhan Bissimbayeva  
**Группа:** ADA-2403M  

## Обзор проекта

В данной практической работе реализованы и сравнены различные алгоритмы сортировки с использованием технологии CUDA для параллельных вычислений на GPU.

### Цели работы:
1. Изучить принципы параллельных вычислений на GPU
2. Реализовать параллельные версии классических алгоритмов сортировки
3. Сравнить производительность CPU и GPU реализаций
4. Сделать выводы об эффективности параллельных алгоритмов


## Описание заданий

###  **Задание 1: Параллельная сортировка слиянием на CUDA**

**Цель:** Реализовать алгоритм сортировки слиянием, адаптированный для параллельного выполнения на GPU.

**Особенности реализации:**
- Массив разделяется на блоки, каждый обрабатывается отдельным блоком потоков
- Локальная сортировка блоков выполняется параллельно
- Слияние отсортированных блоков выполняется иерархически
- Используется shared memory для ускорения доступа к данным

### **Задание 2: Параллельная быстрая сортировка на CUDA**

**Цель:** Адаптировать алгоритм быстрой сортировки для параллельного выполнения на GPU.

**Особенности реализации:**
- Использование параллельных потоков для разделения массива по опорному элементу
- Каждый поток выполняет быструю сортировку на своей части массива
- Иерархическое разделение данных между потоками
- Оптимизация выбора опорного элемента для балансировки нагрузки

### **Задание 3: Параллельная пирамидальная сортировка на CUDA**

**Цель:** Реализовать пирамидальную сортировку с использованием параллельных возможностей GPU.

**Особенности реализации:**
- Параллельное построение двоичной кучи
- Параллельное извлечение максимальных элементов
- Оптимизированное использование памяти GPU
- Минимизация синхронизации между потоками

### **Задание 4: Сравнение производительности**

**Цель:** Проанализировать эффективность параллельных реализаций по сравнению с последовательными.

**Что выполнено:**
- Реализованы последовательные версии всех алгоритмов на CPU
- Измерено время выполнения для массивов разных размеров:
  - 10,000 элементов
  - 100,000 элементов  
  - 1,000,000 элементов
- Проведено сравнение производительности CPU и GPU
- Сделаны выводы на основе результатов измерений

## Инструкция по запуску

### **Требования:**
- Система с GPU NVIDIA (поддержка CUDA)
- Установленный CUDA Toolkit (версия 10.0 или выше)
- Google Colab (рекомендуется) или локальная среда с CUDA

### **Запуск в Google Colab:**

1. **Настройка среды:**
```python
# В Google Colab выбираем GPU среду выполнения:
# Runtime → Change runtime type → Hardware accelerator → GPU
```

2. **Компиляция и запуск каждой задачи:**

**Задание 1 - Сортировка слиянием:**
```bash
!nvcc -arch=sm_75 task_1_cuda.cu -o task_1_cuda && ./task_1_cuda
```

**Задание 2 - Быстрая сортировка:**
```bash
!nvcc -arch=sm_75 task_2_cuda.cu -o task_2_cuda && ./task_2_cuda
```

**Задание 3 - Пирамидальная сортировка:**
```bash
!nvcc -arch=sm_75 task_3_cuda.cu -o task_3_cuda && ./task_3_cuda
```

**Задание 4 - Сравнение производительности:**
```bash
!nvcc -arch=sm_75 task_4_cuda.cu -o task_4_cuda && ./task_4_cuda
```

3. **Объяснение параметров компиляции:**
- `nvcc` - компилятор CUDA
- `-arch=sm_75` - архитектура GPU (для Tesla T4 в Google Colab)
- `task_X_cuda.cu` - исходный файл CUDA
- `-o task_X_cuda` - имя выходного исполняемого файла
- `&& ./task_X_cuda` - последовательный запуск программы после компиляции

### **Запуск на локальной машине:**

1. **Проверка установки CUDA:**
```bash
nvcc --version
nvidia-smi
```

2. **Определение архитектуры GPU:**
```bash
# Для определения правильной архитектуры:
deviceQuery (из примеров CUDA)
# или проверьте модель вашего GPU
```

3. **Компиляция с правильной архитектурой:**
```bash
# Пример для разных архитектур:
# Для GTX 1080: -arch=sm_61
# Для RTX 2080: -arch=sm_75  
# Для A100: -arch=sm_80
```

## Результаты и выводы

### **Ключевые наблюдения:**

1. **Производительность на маленьких массивах:**
   - CPU реализации быстрее из-за накладных расходов на передачу данных CPU↔GPU
   - Пороговое значение: ~50,000 элементов

2. **Производительность на больших массивах:**
   - GPU показывает значительное ускорение для массивов >500,000 элементов
   - Наибольший выигрыш наблюдается у сортировки слиянием

3. **Сравнение алгоритмов:**
   - **На CPU:** Быстрая сортировка показала наилучшую производительность
   - **На GPU:** Сортировка слиянием наиболее эффективно использует параллелизм
   - **Heap Sort:** Стабильная производительность на обеих платформах

### **Технические трудности и решения:**

1. **Проблема:** Наивные GPU реализации часто медленнее CPU
   **Решение:** Использование оптимизированных алгоритмов (битоник-сортировка)

2. **Проблема:** Накладные расходы на копирование данных
   **Решение:** Минимизация передач данных, использование pinned memory

3. **Проблема:** Дисбаланс нагрузки между потоками
   **Решение:** Динамическое распределение работы, оптимизация размера блоков

### **Выводы:**

1. **Эффективность GPU:** GPU эффективен для больших объемов данных (>500K элементов)
2. **Выбор алгоритма:** Зависит от размера данных и требований к стабильности
3. **Сложность реализации:** Параллельные алгоритмы сложнее в реализации, но дают выигрыш в производительности
4. **Практическая применимость:** Для реальных задач рекомендуется использовать оптимизированные библиотеки (Thrust, CUB)

## Технические детали

### **Используемые технологии:**
- **Язык программирования:** C++ с расширениями CUDA
- **Парадигма программирования:** Гетерогенные вычисления (CPU+GPU)
- **Библиотеки:** CUDA Runtime API, STL C++
- **Среда выполнения:** Google Colab с GPU Tesla T4

### **Методология тестирования:**
1. Генерация случайных массивов фиксированных размеров
2. Многократные измерения времени выполнения
3. Проверка корректности сортировки
4. Усреднение результатов для минимизации погрешности

### **Параметры тестирования:**
- Размеры массивов: 10K, 100K, 1M элементов
- Тип данных: 32-битные целые числа
- Количество запусков: 5 для каждого измерения
- Точность измерения: миллисекунды

## Рекомендации для дальнейшей работы

1. **Оптимизация:** Реализовать настоящие GPU-алгоритмы вместо учебных версий
2. **Масштабирование:** Протестировать на массивах до 10 миллионов элементов
3. **Сравнение:** Добавить сравнение с библиотечными реализациями (Thrust)
4. **Визуализация:** Создать графики зависимости времени от размера массива
5. **Профилирование:** Использовать NVIDIA Nsight для детального анализа производительности

##  Полезные команды для отладки

```bash
# Проверка наличия CUDA
!which nvcc

# Проверка версии CUDA
!nvcc --version

# Просмотр информации о GPU
!nvidia-smi

# Компиляция с отладочной информацией
!nvcc -G -arch=sm_75 task_4_cuda.cu -o task_4_cuda_debug

# Запуск с проверкой ошибок CUDA
!cuda-memcheck ./task_4_cuda
```

## Автор проекта  
Студент: Aruzhan Bissimbayeva 

Группа: ADA-2403M

## Преподаватель  
Проверяющий: Sadvakassova Kuralay
